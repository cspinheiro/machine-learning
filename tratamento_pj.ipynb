{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iNowivmfyzLp"
      },
      "source": [
        "\n",
        "# **Limpeza dos Dados**\n",
        "\n",
        "Começando a limpeza dos dados, vamos agora:\n",
        "\n",
        "* Remover duplicatas;\n",
        "\n",
        "* Remover valores missing;\n",
        "\n",
        "* Descartar variáveis com apenas um ou com quantidades muito altas de valores únicos, como mencionado anteriormente¹;\n",
        "\n",
        "* Preencher os valores nulos na coluna `CONFERIR` com `False`, considerando assim que são pessoas sem perfil nessa rede social. Ainda, vamos substituir os valores `True` e `False` nessa coluna por `Sim` e `Não`;\n",
        "\n",
        "* Substituir valores `CONFERIR` e `CONFERIR` na coluna `CONFERIR` por `CONFERIR` e `CONFERIR`, respectivamente.\n",
        "\n",
        "* Descartar linha onde a variável alvo está ausente e transforma os valores da variável alvo para 0 e 1.\n",
        "\n",
        "* Gerar dados sintéticos com SMOTE para equilibrar a variável target²\n",
        "\n",
        "\n",
        "¹É o melhor resultado conhecido\n",
        "\n",
        "²Aparentemente piora o modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cp_8Ivk_1MGQ"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import cross_validate\n",
        "from xgboost import XGBClassifier\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.utils import resample\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gW47cboytw5"
      },
      "source": [
        "# Conferindo valores null\n",
        "base.isnull().sum()\n",
        "\n",
        "# Percentual de null por coluna\n",
        "(COLUNA.isnull().sum() / COLUNA.shape[0] * 100).sort_values(ascending=False)\n",
        "\n",
        "# Removendo valores null\n",
        "base_clean = base.COLUNA.fillna(0) # não tem\n",
        "df.dropna(inplace=True) # não tem\n",
        "\n",
        "# Remover duplicatas\n",
        "base_clean = base_clean.drop_duplicates()\n",
        "\n",
        "# Descartando variáveis\n",
        "drop = ['VARIAVEL1', 'VARIAVEL2']\n",
        "\n",
        "base_clean = base.drop(labels=drop, axis=1)\n",
        "\n",
        "# Lidando com os valores inf\n",
        "base_clean = base_clean[base_clean['reported_income'] != np.inf]\n",
        "\n",
        "# Lidando com os valores negativos\n",
        "base_clean.loc[base_clean['VARIAVEL1'] < 0, 'VARIAVEL2'] = np.nan\n",
        "\n",
        "# Transformando a coluna para Sim ou Não (apenas para visualização) \n",
        "base_clean['COLUNA'].fillna(value=False, inplace=True, axis=0)\n",
        "base_clean['COLUNA'] = base_clean['COLUNA'].map({True: 'Sim', False: 'Não'})\n",
        "\n",
        "# Substituindo valores na coluna email \n",
        "base_clean.loc[base_clean['COLUNA'] == 'CONTEUDO', 'COLUNA'] = 'NOVOCONTEUDO'\n",
        "base_clean.loc[base_clean['COLUNA'] == 'CONTEUDO', 'COLUNA'] = 'NOVOCONTEUDO'\n",
        "\n",
        "# Limpando a variável alvo\n",
        "credito_clean.dropna(subset=['target_default'], inplace=True)\n",
        "credito_clean['target_default'] = credito_clean['target_default'].map({True: 1, False: 0})\n",
        "\n",
        "credito_clean.head()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bonx_nxn3Cw8"
      },
      "source": [
        "# **Tratamento dos Dados**\n",
        "\n",
        "Os valores ausentes nas colunas numéricas serão preenchidos com a mediana da coluna. Já as colunas categóricas terão os valores ausentes substituídos pelos valores presentes na mesma proporção que estes aparacem na coluna. Para tanto, vamos escrever uma função que:\n",
        "\n",
        "Recebe uma coluna;\n",
        "\n",
        "Gera um dicionário onde as chaves são as entradas únicas da coluna e os valores são os percentuais que cada chave representa.\n",
        "\n",
        "A partir do dicionário, cria uma lista de entradas únicas e uma lista de percentuais;\n",
        "\n",
        "Usando estas listas, cria uma série do tamanho da quantidade de valore ausentes na coluna contando os valores presentes na proporção correta\n",
        "\n",
        "Usa a série para preencher os valores ausentes\n",
        "\n",
        "Verifica se há valores ausentes restantes (por questões de arredondamento dos percentuais) e, se sim, o preenche com o valor mais comum.\n",
        "\n",
        "Retorna a coluna preenchida."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rUtk7PQ51ib"
      },
      "source": [
        "# **Balanceando os Dados**\n",
        "# Dividindo e padronizando o dataset original\n",
        "X = credito_clean.drop('target_default', axis=1)\n",
        "y = credito_clean['target_default']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "X_train_unb = scaler.transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Criando o dataset balanceado\n",
        "maioria = base_clean[credito_clean['target_default'] == 0]\n",
        "minoria = base_clean[credito_clean['target_default'] == 1]\n",
        "\n",
        "minoria_balanceada = resample(minoria, replace=True, n_samples=NUMERO)\n",
        "\n",
        "credito_balanceado = pd.concat([maioria, minoria_balanceada])\n",
        "\n",
        "# Dividindo e padronizando o dataset balanceado\n",
        "X_balanceado = credito_balanceado.drop('target_default', axis=1)\n",
        "y_balanceado = credito_balanceado['target_default']\n",
        "\n",
        "X_train_balanceado, X_test_balanceado, y_train_balanceado, y_test_balanceado = train_test_split(X_balanceado, y_balanceado)\n",
        "\n",
        "scaler_balanceado = StandardScaler()\n",
        "scaler_balanceado.fit(X_train_balanceado)\n",
        "X_train_balanceado = scaler_balanceado.transform(X_train_balanceado)\n",
        "X_test_balanceado = scaler_balanceado.transform(X_test_balanceado)\n",
        "\n",
        "# Verificando o balanceamento\n",
        "print(credito_balanceado['target_default'].value_counts(), '\\n')\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8,6))\n",
        "sns.countplot(base_balanceada['target_default'])\n",
        "ax.set_title('Dados após o balanceamento')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-pT5mei3JYS"
      },
      "source": [
        "def preencher_proporcional(col):\n",
        "    \"\"\" Preenche valores ausentes na mesma proporção dos valores presentes\n",
        "\n",
        "    Recebe uma coluna e retorna a coluna com os valores ausentes preenchidos\n",
        "    na proporção dos valores previamente existentes.\"\"\"\n",
        "    \n",
        "    # Gerando o dicionário com valores únicos e sua porcentagens\n",
        "    percentages = col.value_counts(normalize=True).to_dict()\n",
        "\n",
        "    # Tranformando as chaves e valores do dicionário em listas      \n",
        "    percent = [percentages[key] for key in percentages]\n",
        "    labels = [key for key in percentages]\n",
        "\n",
        "    # Utilizando as listas para prencher os valores nulos na proporção correta \n",
        "    s = pd.Series(np.random.choice(labels, p=percent, size=col.isnull().sum()))\n",
        "    col = col.fillna(s)\n",
        "    \n",
        "    # Verificando se todos os valores ausentes foram preenchidos e\n",
        "    # preenchendo os que não tiverem sido\n",
        "    if len(col.isnull()) > 0:\n",
        "        col.fillna(value=max(percentages, key=percentages.get), inplace=True, axis=0)\n",
        "        \n",
        "    return col"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MdiNpnTg5SF8"
      },
      "source": [
        "## **Modelo**\n",
        "\n",
        "Teste com quatro algoritmos diferentes para treinar modelos:\n",
        "* [Regressão Logística](https://pt.wikipedia.org/wiki/Regress%C3%A3o_log%C3%ADstica);\n",
        "* [Árvores de Decisão](https://medium.com/machine-learning-beyond-deep-learning/%C3%A1rvores-de-decis%C3%A3o-3f52f6420b69);\n",
        "* [Random Forest](https://en.wikipedia.org/wiki/Random_forest);\n",
        "* [XGBoost](https://pt.wikipedia.org/wiki/Xgboost).\n",
        "\n",
        "Usando a técnica de [validação cruzada](https://pt.wikipedia.org/wiki/Valida%C3%A7%C3%A3o_cruzada#:~:text=A%20valida%C3%A7%C3%A3o%20cruzada%20%C3%A9%20uma,da%20modelagem%20%C3%A9%20a%20predi%C3%A7%C3%A3o.), vamos ver o desempenho desses quatro algoritmos tanto com os dados balanceados, como com os dados desbalanceados e, portando, teremos oito modelos.\n",
        "Usaremos as seguintes [métricas](https://www.mariofilho.com/as-metricas-mais-populares-para-avaliar-modelos-de-machine-learning/) para avaliar os modelos:\n",
        "\n",
        "* Acurácia;\n",
        "* Precisão;\n",
        "* Recall;\n",
        "* Área sob a curva ROC.\n",
        "\n",
        "Em seguida, vamos gerar um DataFrame com os resultados de cada um dos modelos para facilitar a visualização e a escolha do melhor modelo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYCAn6It3WdC"
      },
      "source": [
        "# **Iterando no DataFrame**\n",
        "\n",
        "Preencher as variáveis categóricas utilizando a função acima;\n",
        "\n",
        "Preencher variáveis numéricas com a mediana."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMymITLL3eNR"
      },
      "source": [
        "for col in base_clean.iloc[:,1:].columns.tolist():\n",
        "    if base_clean[col].dtypes == 'O':\n",
        "        base_clean[col] = preencher_proporcional( base_clean[col])\n",
        "    else:\n",
        "        base_clean[col].fillna(value= base_clean[col].median(), inplace=True, axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QlVG7Pre4KO5"
      },
      "source": [
        "# Preenchendo com a média, ao invés da mediana, para testar\n",
        "\n",
        "for col in base_clean.iloc[:,1:].columns.tolist():\n",
        "    if base_clean[col].dtypes == 'O':\n",
        "        base_clean[col] = preencher_proporcional( base_clean[col])\n",
        "    else:\n",
        "        base_clean[col].fillna(value= base_clean[col].mean(), inplace=True, axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GpUBZXGC4TA-"
      },
      "source": [
        "# Sem valores null\n",
        "\n",
        "base_clean.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8_vq_EI5A43"
      },
      "source": [
        "# **Modelo de Validação Cruzada**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSsWgvNz5Gh-"
      },
      "source": [
        "# Criando os modelos utilizando validação cruzada\n",
        "# Não precisamos, já que o modelo do Dani tá ok\n",
        "logreg_balanceado  = cross_validate(LogisticRegression(solver='liblinear'), X_train_balanceado, y_train_balanceado, cv=5, scoring=['accuracy', 'precision', 'recall', 'roc_auc'])\n",
        "logreg = cross_validate(LogisticRegression(solver='liblinear'), X_train, y_train, cv=5, scoring=['accuracy', 'precision', 'recall', 'roc_auc'])\n",
        "\n",
        "trees_balanceado  = cross_validate(DecisionTreeClassifier(), X_train_balanceado, y_train_balanceado, cv=5, scoring=['accuracy', 'precision', 'recall', 'roc_auc'])\n",
        "trees = cross_validate(DecisionTreeClassifier(), X_train, y_train, cv=5, scoring=['accuracy', 'precision', 'recall', 'roc_auc'])\n",
        "\n",
        "forest_balanceado  = cross_validate(RandomForestClassifier(), X_train_balanceado, y_train_balanceado, cv=5, scoring=['accuracy', 'precision', 'recall', 'roc_auc'])\n",
        "forest = cross_validate(RandomForestClassifier(), X_train, y_train, cv=5, scoring=['accuracy', 'precision', 'recall', 'roc_auc'])\n",
        "\n",
        "xgb_balanceado  = cross_validate(XGBClassifier(), X_train_balanceado, y_train_balanceado, cv=5, scoring=['accuracy', 'precision', 'recall', 'roc_auc'])\n",
        "xgb = cross_validate(XGBClassifier(), X_train, y_train, cv=5, scoring=['accuracy', 'precision', 'recall', 'roc_auc'])\n",
        "\n",
        "# Gerando um DataFrame com os resultados de cada modelo\n",
        "summary = pd.DataFrame({\n",
        "            'labels': ['accuracy', 'precision', 'recall', 'roc_auc'],\n",
        "            'logreg_balanceado': [logreg_balanceado['test_accuracy'].mean(), logreg_balanceado['test_precision'].mean(), logreg_balanceado['test_recall'].mean(), logreg_balanceado['test_roc_auc'].mean()],\n",
        "            'logreg': [logreg['test_accuracy'].mean(), logreg['test_precision'].mean(), logreg['test_recall'].mean(), logreg['test_roc_auc'].mean()],\n",
        "            'trees_balanceado': [trees_balanceado['test_accuracy'].mean(), trees_balanceado['test_precision'].mean(), trees_balanceado['test_recall'].mean(), trees_balanceado['test_roc_auc'].mean()],\n",
        "            'trees': [trees['test_accuracy'].mean(), trees['test_precision'].mean(), trees['test_recall'].mean(), trees['test_roc_auc'].mean()],\n",
        "            'forest_balanceado': [forest_balanceado['test_accuracy'].mean(), forest_balanceado['test_precision'].mean(), forest_balanceado['test_recall'].mean(), forest_balanceado['test_roc_auc'].mean()],\n",
        "            'forest': [forest['test_accuracy'].mean(), forest['test_precision'].mean(), forest['test_recall'].mean(), forest['test_roc_auc'].mean()],\n",
        "            'xgb_balanceado': [xgb_balanceado['test_accuracy'].mean(), xgb_balanceado['test_precision'].mean(), xgb_balanceado['test_recall'].mean(), xgb_balanceado['test_roc_auc'].mean()],\n",
        "            'xgb': [xgb['test_accuracy'].mean(), xgb['test_precision'].mean(), xgb['test_recall'].mean(), xgb['test_roc_auc'].mean()]           \n",
        "}).set_index('labels')\n",
        "summary.index.name=None\n",
        "summary = summary.transpose()    \n",
        "summary.style.applymap(lambda x: 'background-color: lightgreen' if x >= 0.75 else '')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}